{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Tf-IDF\n",
    "\n",
    "In this notebook you will be exploring the computation of the Tf-IDF feature using a very popular dataset called 20 newsgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 20 newsgroups by date dataset\n",
      "Number of posts 11314\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUqv/D6MOnIMuR98ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a7ce3150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First post!\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.cross_validation as cvs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegressio\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "post_texts = data.data\n",
    "news_group_ids = data.target\n",
    "\n",
    "print data.description\n",
    "\n",
    "print \"Number of posts\", len(data.data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data.target, bins=20)\n",
    "plt.xlabel('Newsgroup Id')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.show()\n",
    "\n",
    "print \"First post!\"\n",
    "print data.data[0]\n",
    "\n",
    "print data.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will be writing a function to compute the term frequency part of [Tf-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).  It's up to you how fancy to make this function.  In my simple version, I used split after first removing leading or trailing punctuation (I used the `strip` function) and also converting the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'a': 3,\n",
       " u'addition': 1,\n",
       " u'all': 1,\n",
       " u'anyone': 2,\n",
       " u'be': 1,\n",
       " u'body': 1,\n",
       " u'bricklin': 1,\n",
       " u'bumper': 1,\n",
       " u'called': 1,\n",
       " u'can': 1,\n",
       " u'car': 4,\n",
       " u'could': 1,\n",
       " u'day': 1,\n",
       " u'doors': 1,\n",
       " u'early': 1,\n",
       " u'engine': 1,\n",
       " u'enlighten': 1,\n",
       " u'from': 2,\n",
       " u'front': 1,\n",
       " u'funky': 1,\n",
       " u'have': 1,\n",
       " u'history': 1,\n",
       " u'i': 3,\n",
       " u'if': 2,\n",
       " u'in': 1,\n",
       " u'info': 1,\n",
       " u'is': 2,\n",
       " u'it': 2,\n",
       " u'know': 1,\n",
       " u'late': 1,\n",
       " u'looked': 1,\n",
       " u'looking': 1,\n",
       " u'made': 1,\n",
       " u'me': 1,\n",
       " u'model': 1,\n",
       " u'name': 1,\n",
       " u'of': 2,\n",
       " u'on': 2,\n",
       " u'or': 1,\n",
       " u'other': 1,\n",
       " u'out': 1,\n",
       " u'please': 1,\n",
       " u'production': 1,\n",
       " u'really': 1,\n",
       " u'rest': 1,\n",
       " u'saw': 1,\n",
       " u'separate': 1,\n",
       " u'small': 1,\n",
       " u'specs': 1,\n",
       " u'sports': 1,\n",
       " u'tellme': 1,\n",
       " u'the': 6,\n",
       " u'there': 1,\n",
       " u'this': 4,\n",
       " u'to': 1,\n",
       " u'was': 4,\n",
       " u'were': 1,\n",
       " u'whatever': 1,\n",
       " u'where': 1,\n",
       " u'wondering': 1,\n",
       " u'years': 1,\n",
       " u'you': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def tf(text):\n",
    "    \"\"\" Returns a dictionary where keys are words that occur in text\n",
    "        and the value is the number of times that each word occurs. \"\"\"\n",
    "    d = {}\n",
    "    words = text.split()\n",
    "    for w in words:\n",
    "        modified_word = w.lower().strip('.,;!?\"()')\n",
    "        if not modified_word.strip(string.ascii_letters):\n",
    "            d[modified_word] = d.get(modified_word,0) + 1\n",
    "    return d\n",
    "\n",
    "tf(data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will be writing a function to compute the inverse document frequency part of [Tf-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest IDF (most common)\n",
      "(u'the', 0.1783344654369077)\n",
      "(u'to', 0.2951935671812279)\n",
      "(u'a', 0.3093035704974311)\n",
      "(u'and', 0.37938084476550754)\n",
      "(u'of', 0.38963734493269664)\n",
      "(u'i', 0.4496015428308278)\n",
      "(u'in', 0.4708878807844732)\n",
      "(u'is', 0.4824190783836629)\n",
      "(u'that', 0.560876083276634)\n",
      "(u'it', 0.5843807692394498)\n",
      "\n",
      "Highest IDF (least common)\n",
      "(u'jawbone', 9.333796175903101)\n",
      "(u'codings', 9.333796175903101)\n",
      "(u'anime', 9.333796175903101)\n",
      "(u'tzeng', 9.333796175903101)\n",
      "(u'corelations', 9.333796175903101)\n",
      "(u'echte', 9.333796175903101)\n",
      "(u'geysers', 9.333796175903101)\n",
      "(u'crete', 9.333796175903101)\n",
      "(u'rlequant', 9.333796175903101)\n",
      "(u'moguls', 9.333796175903101)\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import operator\n",
    "\n",
    "def idf(data):\n",
    "    \"\"\" Returns a dictionary where the keys are words and the values are inverse\n",
    "        document frequencies.  For this function you should use the formula\n",
    "        idf(w, data) = log(N / |text in data that contain the word w|) \"\"\"\n",
    "    document_count = {}\n",
    "    for post in data:\n",
    "        d = tf(post)\n",
    "        for k in d:\n",
    "            document_count[k] = document_count.get(k, 0) + 1\n",
    "    \n",
    "    idf = {}\n",
    "    for key in document_count:\n",
    "        idf[key] = log(len(data)/float(document_count[key]))\n",
    "    return idf\n",
    "\n",
    "idf_dict = idf(data.data)\n",
    "sorted_idf = sorted(idf_dict.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print \"Lowest IDF (most common)\"\n",
    "for d in sorted_idf[0:10]:\n",
    "    print d\n",
    "\n",
    "print \"\"\n",
    "print \"Highest IDF (least common)\"\n",
    "rev_sorted_idf = sorted(idf_dict.items(), key=operator.itemgetter(1))\n",
    "for d in reversed(rev_sorted_idf[-10:]):\n",
    "    print d\n",
    "    \n",
    "    \n",
    "idfVal = idf(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tf-IDF and Document Classification\n",
    "\n",
    "Next, you will be using these functions to create a model to classify the newsgroup documents.  Here is an outline of the basic steps you will need to take to do this.\n",
    "\n",
    "1.  Create a tfidf function that combines your tf and idf function to process a string and returns the TF-IDF features for that string expressed as a Python dictionary.\n",
    "2.  Create a function that takes a list of strings (a dataset) and returns a matrix consisting of the TF-IDF features for each string expressed as a vector.  This will require you to think about how to map a specific word to a specific element of your vector.  You will have to think about whether to store your data as a sparse or dense matrix.\n",
    "3.  Use your vectorizer on the news group data.  Then use something like cross_val_score to estimate the performance of your model.  Start with a subset of the data so you get a sense for the training time.  For your classifier, you can try different options.  Some good ones to look at would be Support Vector Classifiers, Logistic Regression, and RandomForests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'body': 3.8784750605453997, u'all': 1.2907752906048189, u'the': 1.0700067926214463, u'is': 0.9648381567673258, u'out': 1.5173791922113, u'history': 3.706175062212464, u'it': 1.1687615384788996, u'rest': 3.584403189994848, u'years': 2.5358557629281706, u'production': 5.129103556512135, u'have': 0.773160426644027, u'in': 0.4708878807844732, u'saw': 3.7616421437253367, u'specs': 5.239451613681, u'enlighten': 6.768846818441564, u'anyone': 4.222460314161861, u'from': 2.4110120085920994, u'bricklin': 8.640648995343156, u'there': 1.2930271815355219, u'please': 2.2871488980543453, u'sports': 5.239451613681, u'late': 4.197997738852839, u'to': 0.2951935671812279, u'other': 1.6812504832091804, u'wondering': 4.157646443329272, u'you': 0.8240305003156602, u'really': 2.382981407460517, u'was': 4.994469711314258, u'engine': 4.413815250074976, u'be': 0.8313106133591379, u'doors': 5.527133686132781, u'separate': 4.481765911983484, u'addition': 4.296843573489472, u'early': 3.750299867121402, u'me': 1.4628665791479585, u'were': 1.904868981100829, u'if': 1.8712235421381316, u'whatever': 3.670835695767155, u'front': 3.917695773698681, u'day': 3.031177200158196, u'a': 0.9279107114922933, u'on': 1.5873360264087353, u'made': 2.6417124333964725, u'name': 3.143480770049954, u'car': 13.574499692730678, u'i': 1.3488046284924835, u'of': 0.7792746898653933, u'could': 1.9162157734885568, u'this': 3.0826962103938547, u'called': 3.0005165477634104, u'looked': 4.071105986998216, u'tellme': 9.333796175903101, u'funky': 7.724358263469001, u'info': 3.510750280420082, u'can': 1.2167820881657907, u'bumper': 6.443424418006936, u'small': 3.2653705876589907, u'model': 3.917695773698681, u'looking': 2.993436872175349, u'where': 2.213351803510613, u'or': 0.9821854252765418, u'know': 1.6097915192270351}\n"
     ]
    }
   ],
   "source": [
    "def tfidf(document, idfVal):\n",
    "    \n",
    "    tf_vals = tf(document)\n",
    "        \n",
    "    return {word: tf_val*idfVal[word] for word, tf_val in tf_vals.items()}\n",
    "    \n",
    "print tfidf(data.data[0], idfVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.lil.lil_matrix'>\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "def construct_matrix(data, idfVal):\n",
    "    \n",
    "    word_ind = dict(zip(idfVal.keys(), xrange(len(idf_dict))))\n",
    "\n",
    "    matrix = sparse.lil_matrix((len(data), len(idfVal)))\n",
    "    \n",
    "    for i, doc in enumerate(data):\n",
    "        tfidf_dict = tfidf(doc, idfVal)\n",
    "        \n",
    "        for word, tfidf_val in tfidf_dict.iteritems():\n",
    "            matrix[i, word_ind[word]] = tfidf_val\n",
    "    \n",
    "    return matrix\n",
    "    \n",
    "matrix = construct_matrix(data.data, idfVal)\n",
    "\n",
    "print type(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7b32073132f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "scores = cvs.cross_val_score(alg, matrix[:5000,:], data.target[:5000], cv=3)\n",
    "\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
